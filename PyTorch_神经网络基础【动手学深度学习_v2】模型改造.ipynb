{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/one-pieces/google-colab/blob/main/PyTorch_%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E3%80%90%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_v2%E3%80%91%E6%A8%A1%E5%9E%8B%E6%94%B9%E9%80%A0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch 神经网络基础【动手学深度学习 v2】模型改造"
      ],
      "metadata": {
        "id": "w1JTzg4fqBTG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X4jmLb2VLhRA",
        "outputId": "cb07cd4b-8cde-4f68-fa12-fab2515cb8e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.0249, -0.0253,  0.2287,  0.2033, -0.2314, -0.1831,  0.0070, -0.2411,\n",
              "         -0.0624,  0.1612],\n",
              "        [ 0.1597, -0.0555,  0.1794,  0.0634, -0.2676, -0.3104, -0.1404, -0.1232,\n",
              "         -0.2079,  0.0573]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
        "\n",
        "X = torch.rand(2, 20)\n",
        "net(X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden = nn.Linear(20, 256)\n",
        "    self.out = nn.Linear(256, 10)\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.out(F.relu(self.hidden(X)))"
      ],
      "metadata": {
        "id": "NWyEOux-n5G1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = MLP()\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilwj6OPsohEG",
        "outputId": "c6ad044b-7c01-4cd4-f536-a8512a59ca07"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1369, -0.1060,  0.0999,  0.0954, -0.0040,  0.0170,  0.2150, -0.0786,\n",
              "          0.1681, -0.1319],\n",
              "        [ 0.1942, -0.1665, -0.0275,  0.1443, -0.1072,  0.0495,  0.2852,  0.0116,\n",
              "          0.1548, -0.1941]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MySequential(nn.Module):\n",
        "  def __init__(self, *args):\n",
        "    super().__init__()\n",
        "    for block in args:\n",
        "        self._modules[block] = block\n",
        "    \n",
        "  def forward(self, X):\n",
        "    for block in self._modules.values():\n",
        "      X = block(X)\n",
        "    return X\n",
        "\n",
        "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPkcD_pPowM0",
        "outputId": "2fe71809-550a-431d-9801-54896a091f1e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3376, -0.0719, -0.2315,  0.0048,  0.2171, -0.1195,  0.0845, -0.1003,\n",
              "          0.0900, -0.1064],\n",
              "        [ 0.1855, -0.1155, -0.1918, -0.2293,  0.0741, -0.1637, -0.0142, -0.1371,\n",
              "         -0.0759, -0.1068]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "在正向传播函数中执行代码"
      ],
      "metadata": {
        "id": "QiDwTo-rpv2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FixedHiddenMLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.rand_weight = torch.rand((20, 20), requires_grad = False)\n",
        "    self.linear = nn.Linear(20, 20)\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = self.linear(X)\n",
        "    X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
        "    X = self.linear(X)\n",
        "    while X.abs().sum() > 1:\n",
        "      X /= 2\n",
        "    return X.sum()\n",
        "\n",
        "net = FixedHiddenMLP()\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSCLiFXlpz0D",
        "outputId": "f9f2b1f2-0904-402b-d3ff-b3334acc17ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.0510, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "混合搭配各种组合块的方法"
      ],
      "metadata": {
        "id": "93xj5KCSr8fX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NestMLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(), nn.Linear(64, 32), nn.ReLU())\n",
        "    self.linear = nn.Linear(32, 16)\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.linear(self.net(X))\n",
        "\n",
        "chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())\n",
        "chimera(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltYl4AMJsBwD",
        "outputId": "ae083f6c-c76e-4c02-a543-d2922d46f181"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1710, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9BQyJTA/sY/v7X5ZsI1wg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}